---
title: "Lecture 16 - Logistic Regression with Regularization"
author: "Material based on statistical learning with sparsity (Trevor Hastie, Robert Tibshirani and Martin Wainwright) - Presented by Renato Rodrigues Silva"
institute: "Federal University of Goias."
date: "(updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false


---
class: middle
##Example 2 - Student Performance Data Set

###Data Set Information:

- This dataset describes the student performance in secondary education of two Portuguese schools. 

- Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008]

- Here, we are going to use only the dataset regarded to Portuguese

- The dataset was modeled under binary/five-level classification task.

- **Important note**: the target attribute G3 has a strong correlation with attributes G2 and G1. 

- This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades.

- It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).


---
class: middle
###Attribute Information:

- **school** - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
- **sex** - student's sex (binary: 'F' - female or 'M' - male)
- **age** - student's age (numeric: from 15 to 22)
- **address** - student's home address type (binary: 'U' - urban or 'R' - rural)
- **famsize** - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)
- **Pstatus** - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
- **Medu** - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education)
- **Fedu** - father's education  (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education)
- **Mjob** - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
- **Fjob** - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')

---
class: middle
###Attribute Information:


- **reason** - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')
- **guardian** - student's guardian (nominal: 'mother', 'father' or 'other')
- **traveltime** - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)
- **studytime** - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
- **failures** - number of past class failures (numeric: n if 1<=n<3, else 4)
- **schoolsup** - extra educational support (binary: yes or no)
- **famsup** - family educational support (binary: yes or no)
- **paid** - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
- **activities** - extra-curricular activities (binary: yes or no)
- **nursery** - attended nursery school (binary: yes or no)


---
class: middle
###Attribute Information:


- **higher** - wants to take higher education (binary: yes or no)
- **internet** - Internet access at home (binary: yes or no)
- **romantic** - with a romantic relationship (binary: yes or no)
- **famrel** - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
- **freetime** - free time after school (numeric: from 1 - very low to 5 - very high)
- **goout** - going out with friends (numeric: from 1 - very low to 5 - very high)
- **Dalc** - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
- **Walc** - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
- **health** - current health status (numeric: from 1 - very bad to 5 - very good)
- **absences** - number of school absences (numeric: from 0 to 93)


---
class: middle
###Outcome:

- **G1** - first period grade (numeric: from 0 to 20)

- **G2** - second period grade (numeric: from 0 to 20)

- **G3** - final grade (numeric: from 0 to 20, output target)

- We are going to format the outcome as follows:

- $0 \leq G < 4 \Rightarrow E;$

- $4 \leq G < 8  \Rightarrow D;$

- $8 \leq G < 12  \Rightarrow C;$

- $12 \leq G < 18  \Rightarrow B;$

- $18\leq G < 20  \Rightarrow A.$

---
class: middle
###Multinomial logistic regression


The model has the form

$$\log\left\{\frac{Pr(G=k|X=\mathbf{x})}{Pr(G=K|X=\mathbf{x})}\right\} = \beta_{k0} + \boldsymbol{\beta}_{k}^{'}\mathbf{x},\phantom{111} k = 1, \ldots, K-1.$$

###Names of Variables

```{r,warning = FALSE, message = FALSE, echo=FALSE}
library(tidyverse)
library(glmnet)
library(nnet)
library(caret)
library(pROC)
library(multiROC)

dat =  read.csv2("student-por.csv", header = TRUE)

Grades = c(-Inf,4,8,12,18,Inf)
Grades_l = c("E","D","C","B", "A")

dat = mutate(dat,
            G1_final = cut(G2,include.lowest=TRUE, right=FALSE,
                           breaks=Grades, labels=Grades_l), 
            G2_final = cut(G2,include.lowest=TRUE, right=FALSE,
                           breaks=Grades, labels=Grades_l),
            G3_final = cut(G3,include.lowest=TRUE, right=FALSE,
                           breaks=Grades, labels=Grades_l)
             ) %>% select(-G1) %>% select(-G2) %>% select(-G3) 

names(dat)


```



---
class: middle
###Multinomial logistic regression


```{r,warning = FALSE, message = FALSE, echo=FALSE}

set.seed(42)
dat_idx = sample(nrow(dat), round(0.7*nrow(dat)))
dat_trn = dat[dat_idx, ]
dat_tst = dat[-dat_idx, ]


full.model <- multinom(G3_final ~ ., data = dat_trn,trace=FALSE,decay=0)

round(summary(full.model)$coefficients,2)


```


---
class: middle
###Multinomial logistic regression


```{r,warning = FALSE, message = FALSE, echo=FALSE}

full_mod_cv = train(
  G3_final ~ .,
  data = dat_trn,
  method = "multinom",
  trControl = trainControl(method = "cv", number = 10),
  trace = FALSE
)

print(full_mod_cv)


```


[Source:](http://www.cpaqv.org/estatistica/kappa.pdf)

[Decay:](https://stackoverflow.com/questions/9390337/purpose-of-decay-parameter-in-nnet-function-in-r/35096148)

[Decay 2:](https://stats.stackexchange.com/questions/29130/difference-between-neural-net-weight-decay-and-learning-rate)


---
class: middle
###AUC - pROC package


```{r,warning = FALSE, message = FALSE, echo=FALSE}

full.model.decay0.1 <- multinom(G3_final ~ ., data = dat_trn,trace=FALSE,decay=0.1)

proc = multiclass.roc(dat_tst$G3_final, 
               predict(full.model.decay0.1, newdata = dat_tst, type = "prob"))

print(proc)
```

[Method:](https://link.springer.com/article/10.1023%2FA%3A1010920819831)


- The AUC is equivalent to the probability that a randomly chosen member of one class has a smaller estimated probability of belonging to the other class than has a randomly chosen member of the other class. 

- And so is a natural measure of separability between the two estimated probability distributions. 




---
class: middle
###ROC curve - multiROC package


```{r,warning = FALSE, message = FALSE, echo=FALSE}

mn_pred = predict(full.model.decay0.1, newdata = dat_tst, type = "prob")
mn_pred <- data.frame(mn_pred)
colnames(mn_pred) <- paste(colnames(mn_pred), "_pred_MN")


true_label <- dummies::dummy(dat_tst$G3_final, sep = ".")
true_label <- data.frame(true_label)
colnames(true_label) <- gsub(".*?\\.", "", colnames(true_label))
colnames(true_label) <- paste(colnames(true_label), "_true")
final_df <- cbind(true_label, mn_pred)

roc_res <- multi_roc(final_df, force_diag=T)
plot_roc_df <- plot_roc_data(roc_res)


ggplot(plot_roc_df, aes(x = 1-Specificity, y=Sensitivity)) +
  geom_path(aes(color = Group), size=1.5) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
                        colour='grey', linetype = 'dotdash') +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), 
                 legend.justification=c(1, 0), legend.position=c(.95, .05),
                 legend.title=element_blank(), 
                 legend.background = element_rect(fill=NULL, size=0.5,                                                linetype="solid", colour ="black"))


```


---
class: middle
###AUC - multiROC package

```{r,warning = FALSE, message = FALSE, echo=FALSE}

unlist(roc_res$AUC)
```

[Source:](https://github.com/WandeRum/multiROC)

[Source2:](https://mran.microsoft.com/snapshot/2018-02-12/web/packages/multiROC/vignettes/my-vignette.html)


- The AUC is the probability the model will score a randomly chosen positive class higher than a randomly chosen negative class. 


---
class: middle
###Multinomial logistic regression - `glmnet` package

For the multinomial model, suppose the response variable has $K$ levels
${\call G} = \left\{1, 2, \ldots, \right\}.$ 

Here, the model is the following

$$\log\left\{\frac{Pr(G=k|X=\mathbf{x})}{Pr(G=K|X=\mathbf{x})}\right\} = \beta_{k0} + \boldsymbol{\beta}_{k}^{'}\mathbf{x},\phantom{111} k = 1, \ldots, K-1.$$

Let $Y$ be the $N \times K$ indicator response matrix, with elements $y_{il} = I(g_i=l)$. The log-likelihood is given by

$$l(\boldsymbol{\beta}) = -\left[\frac{1}{N}\sum_{i=1}^N\left(\sum_{k=1}^K y_{il}(\beta_{0k}+x_i^{'}\beta_k) - \log(\sum_{k=1}^K e^{\beta_{0k} + x_i^{'}\beta_k}) \right)\right] + \lambda \sum_{j=1}^p||\beta_j||_{1},$$

---
class: middle
###Multinomial logistic regression - `glmnet` package



```{r,warning = FALSE, message = FALSE, echo=FALSE}

x = model.matrix(G3_final ~ 0+., data= dat_trn)

y = dat_trn$G3_final  


#glmnet(x, y, family = "multinomial", 
#       type.multinomial = "grouped")
  
cvfit=cv.glmnet(x,y,
                family="multinomial", nfolds=5,
                type.multinomial = "grouped",  alpha=1)
plot(cvfit)


```

---
class: middle
###Multinomial logistic regression - `glmnet` package

```{r,warning = FALSE, message = FALSE, echo=FALSE}

mcoef = coef(cvfit, s = "lambda.min")

mcoef = data.frame(nam = rownames(mcoef$E),
           E = round(as.vector(mcoef$E),3), 
           D = round(as.vector(mcoef$D),3),
           C = round(as.vector(mcoef$C),3),
           B = round(as.vector(mcoef$B),3),
           A = round(as.vector(mcoef$A),3)
) 
mcoef[1:23,]
```

---
class: middle
###Multinomial logistic regression - `glmnet` package

```{r,warning = FALSE, message = FALSE, echo=FALSE}


mcoef[24:nrow(mcoef),]
```

---
class: middle
###ROC curve - multiROC package


```{r,warning = FALSE, message = FALSE, echo=FALSE}

x_tst = model.matrix(G3_final ~ ., data= dat_tst)


mn_pred = predict(cvfit, newx = x_tst, s = "lambda.min", type = "response")
mn_pred <- data.frame(mn_pred[,,1])
colnames(mn_pred) <- paste(colnames(mn_pred), "_pred_MN")


true_label <- dummies::dummy(dat_tst$G3_final, sep = ".")
true_label <- data.frame(true_label)
colnames(true_label) <- gsub(".*?\\.", "", colnames(true_label))
colnames(true_label) <- paste(colnames(true_label), "_true")
final_df <- cbind(true_label, mn_pred)

roc_res <- multi_roc(final_df, force_diag=T)
plot_roc_df <- plot_roc_data(roc_res)


ggplot(plot_roc_df, aes(x = 1-Specificity, y=Sensitivity)) +
  geom_path(aes(color = Group), size=1.5) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
                        colour='grey', linetype = 'dotdash') +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), 
                 legend.justification=c(1, 0), legend.position=c(.95, .05),
                 legend.title=element_blank(), 
                 legend.background = element_rect(fill=NULL, size=0.5,                                                linetype="solid", colour ="black"))


```

---
class: middle
###AUC - multiROC package

```{r,warning = FALSE, message = FALSE, echo=FALSE}

unlist(roc_res$AUC)
```